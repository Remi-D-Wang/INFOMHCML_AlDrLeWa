{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb19070",
   "metadata": {},
   "source": [
    "## ACS PUMS: recent adult datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718161e",
   "metadata": {},
   "source": [
    "How to use folktables please refer to https://github.com/socialfoundations/folktables.git\n",
    "- e.g. the defination of adult_filter can be found at https://github.com/socialfoundations/folktables/blob/main/folktables/acs.py\n",
    "\n",
    "<span style=\"color:red\">Quick note about the tool:</span>\n",
    "The original paper (https://arxiv.org/pdf/2108.04884v3) provides detailed descriptions of datasets like ACSIncome and ACSEmployment, including their specific features and filter conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4291ed",
   "metadata": {},
   "source": [
    "**The ```ACSIncome``` function:**\n",
    "1. comes with default configurations:\n",
    "- Features(float): AGEP,COW,SCHL,MAR,OCCP,POBP,RELP,WKHP,SEX,RAC1P\n",
    "- Labels(boolean): PINCP\n",
    "\n",
    "2. ```adult_filter``` criteria:\n",
    "- AGEP (Age): Must be greater than 16\n",
    "- PINCP (Total person’s income): Must be greater than 100\n",
    "- WKHP (Usual hours worked per week past 12 months): Must be greater than 0\n",
    "- PWGTP (Person weight (relevant for re-weighting dataset to represent the general US population most accurately)): Must be greater than or equal to 1\n",
    "\n",
    "**The ```ACSEmployment``` function:**\n",
    "1. comes with default configurations:\n",
    "- Features(float):'AGEP','SCHL','MAR','SEX','DIS','ESP','MIG','CIT','MIL','ANC','NATIVITY','RELP','DEAR','DEYE','DREM','RAC1P','GCL'\n",
    "- Labels(boolean):'ESR'\n",
    "- **The label should be <span style=\"color:red\">'ESR'</span>**. According to the documentation, the feature ‘NWLA’ (On layoff from work) is UNEDITED – see ‘Employment Status Recode’ (ESR).\n",
    "2. ```employment_filter``` criteria:\n",
    "- AGEP (Age) must be greater than 16 and less than 90.\n",
    "- PWGTP (Person weight) must be greater than or equal to 1.\n",
    "\n",
    "In both datasets, **we dropped the ‘RELP’ feature** because it is not available in the 2023 dataset, and we want to ensure that all features are consistent across years. See code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9c534",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264ec83",
   "metadata": {},
   "source": [
    "### Assign OCCP Top-Level Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ba8cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation recode for 2012 and later based on 2010 OCC codes\n",
      "Occupation recode for 2018 and later based on 2018 OCC codes\n",
      "     code                                explanation category_prefix  \\\n",
      "0  2000.0                             CMS-COUNSELORS             CMS   \n",
      "1  3160.0                    MED-Physical Therapists             MED   \n",
      "2  3820.0  PRT-Detectives And Criminal Investigators             PRT   \n",
      "3  5200.0                       OFF-BROKERAGE CLERKS             OFF   \n",
      "4  5220.0   OFF-Court, Municipal, And License Clerks             OFF   \n",
      "\n",
      "   category_code                           category_name  \n",
      "0            5.0            Community and Social Service  \n",
      "1            9.0  Healthcare Practitioners and Technical  \n",
      "2           11.0                      Protective Service  \n",
      "3            1.0       Office and Administrative Support  \n",
      "4            1.0       Office and Administrative Support  \n",
      "Size of df_OCCP:  (631, 5)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API URL of OCCP \"Occupation\"\n",
    "url_2014 = \"https://api.census.gov/data/2014/acs/acs1/pums/variables/OCCP.json\"\n",
    "url_2023 = \"https://api.census.gov/data/2023/acs/acs1/pums/variables/OCCP.json\"\n",
    "response_2014 = requests.get(url_2014)\n",
    "response_2023 = requests.get(url_2023)\n",
    "data_2014 = response_2014.json()\n",
    "data_2023 = response_2023.json()\n",
    "\n",
    "# OCCP\n",
    "print(data_2014['label'])\n",
    "print(data_2023['label'])\n",
    "\n",
    "dict_2014 = data_2014['values']['item']\n",
    "dict_2023 = data_2023['values']['item']\n",
    "# Merging the two dictionaries and cover\n",
    "# Keys present in both 2014 and 2023 are updated with 2023 values.\n",
    "values_dict = {**dict_2014, **dict_2023}\n",
    "\n",
    "df_OCCP = pd.DataFrame.from_dict(values_dict, orient='index', columns=['explanation'])\n",
    "df_OCCP = df_OCCP.reset_index().rename(columns={'index': 'code'})\n",
    "df_OCCP = df_OCCP[df_OCCP['code'] != 'N']\n",
    "df_OCCP['code'] = df_OCCP['code'].astype(float)\n",
    "# Extracting the first word as the category if it exists, otherwise set it to None\n",
    "df_OCCP['category_prefix'] = df_OCCP['explanation'].str.extract(r'^([^-\\s]+)-')\n",
    "\n",
    "# Full Name Mapping\n",
    "prefix_dict = {\n",
    "    \"MGR\": \"Manager\",\n",
    "    \"OFF\": \"Office and Administrative Support\",\n",
    "    \"EAT\": \"Food Preparation and Serving Related\",\n",
    "    \"PRD\": \"Production\",\n",
    "    \"TRN\": \"Transportation and Material Moving\",\n",
    "    \"CMS\": \"Community and Social Service\",\n",
    "    \"BUS\": \"Business and Financial Operations\",\n",
    "    \"ENG\": \"Engineers\",\n",
    "    \"SCI\": \"Scientists\",\n",
    "    \"MED\": \"Healthcare Practitioners and Technical\",\n",
    "    \"HLS\": \"Healthcare Support\",\n",
    "    \"PRT\": \"Protective Service\",\n",
    "    \"EDU\": \"Education, Training, and Library\",\n",
    "    \"ENT\": \"Arts, Design, Entertainment, Sports, and Media\",\n",
    "    \"LGL\": \"Legal\",\n",
    "    \"SAL\": \"Sales and Related\",\n",
    "    \"PRS\": \"Personal Care and Service\",\n",
    "    \"CLN\": \"Building and Grounds Cleaning and Maintenance\",\n",
    "    \"CON\": \"Construction and Extraction\",\n",
    "    \"RPR\": \"Installation, Maintenance, and Repair\",\n",
    "    \"FFF\": \"Farming, Fishing, and Forestry\",\n",
    "    \"CMM\": \"Computer and Mathematical\",\n",
    "    \"FIN\": \"Financial Specialists\",\n",
    "    \"EXT\": \"Extraction Workers\",\n",
    "    \"MIL\": \"Military Specific\"\n",
    "}\n",
    "\n",
    "prefix_code_dict = {k: i for i, k in enumerate(prefix_dict.keys())}\n",
    "df_OCCP['category_code'] = df_OCCP['category_prefix'].map(prefix_code_dict)\n",
    "df_OCCP['category_name'] = df_OCCP['category_prefix'].map(prefix_dict)\n",
    "\n",
    "print(df_OCCP.head())\n",
    "print(\"Size of df_OCCP: \", df_OCCP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1727cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 631 entries, 0 to 631\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   code             631 non-null    float64\n",
      " 1   explanation      631 non-null    object \n",
      " 2   category_prefix  629 non-null    object \n",
      " 3   category_code    629 non-null    float64\n",
      " 4   category_name    629 non-null    object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 29.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_OCCP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951982f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_prefix</th>\n",
       "      <th>category_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMS</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRT</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CON</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FIN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HLS</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MIL</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CMM</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EDU</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EAT</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRS</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SAL</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RPR</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRD</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MGR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ENG</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ENT</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SCI</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FFF</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>BUS</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>EXT</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>LGL</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>CLN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category_prefix  category_code\n",
       "0               CMS            5.0\n",
       "1               MED            9.0\n",
       "2               PRT           11.0\n",
       "3               OFF            1.0\n",
       "5               TRN            4.0\n",
       "7               CON           18.0\n",
       "8               NaN            NaN\n",
       "9               FIN           22.0\n",
       "10              HLS           10.0\n",
       "11              MIL           24.0\n",
       "13              CMM           21.0\n",
       "14              EDU           12.0\n",
       "16              EAT            2.0\n",
       "17              PRS           16.0\n",
       "18              SAL           15.0\n",
       "20              RPR           19.0\n",
       "21              PRD            3.0\n",
       "25              MGR            0.0\n",
       "37              ENG            7.0\n",
       "38              ENT           13.0\n",
       "45              SCI            8.0\n",
       "47              FFF           20.0\n",
       "70              BUS            6.0\n",
       "144             EXT           23.0\n",
       "160             LGL           14.0\n",
       "230             CLN           17.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OCCP[['category_prefix', 'category_code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab4e63",
   "metadata": {},
   "source": [
    "### Require Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3be821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2014 1-Year person survey for CA...\n",
      "Downloading data for 2023 1-Year person survey for CA...\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSIncome, ACSEmployment, BasicProblem, adult_filter, employment_filter\n",
    "import numpy as np\n",
    "\n",
    "# Dropping 'RELP' since it is not available in 2023 dataset\n",
    "ACSIncomeNew = BasicProblem( \n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 50000,    \n",
    "    group='RAC1P',\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "ACSEmploymentNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'SEX',\n",
    "        'DIS',\n",
    "        'ESP',\n",
    "        'MIG',\n",
    "        'CIT',\n",
    "        'MIL',\n",
    "        'ANC',\n",
    "        'NATIVITY',\n",
    "        'DEAR',\n",
    "        'DEYE',\n",
    "        'DREM',\n",
    "        'RAC1P',\n",
    "        'GCL',\n",
    "    ],\n",
    "    target=\"ESR\",\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='RAC1P',\n",
    "    preprocess=employment_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "data_source_2014 = ACSDataSource(survey_year='2014', horizon='1-Year', survey='person')\n",
    "ca_data_2014 = data_source_2014.get_data(states=[\"CA\"], download=True) # California\n",
    "\n",
    "data_source_2023 = ACSDataSource(survey_year='2023', horizon='1-Year', survey='person')\n",
    "ca_data_2023 = data_source_2023.get_data(states=[\"CA\"], download=True) # California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85995779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income Data\n",
    "ca_features_2023, ca_labels_2023, _ = ACSIncomeNew.df_to_pandas(ca_data_2023)\n",
    "ca_features_2014, ca_labels_2014, _ = ACSIncomeNew.df_to_pandas(ca_data_2014)\n",
    "\n",
    "# Employment Data\n",
    "ca_features_2014_em, ca_labels_2014_em, _ = ACSEmploymentNew.df_to_pandas(ca_data_2014)\n",
    "ca_features_2023_em, ca_labels_2023_em, _ = ACSEmploymentNew.df_to_pandas(ca_data_2023)\n",
    "\n",
    "# True 1 False 0, 1 = > 50K, 0 = <= 50K\n",
    "mapping = {True: 1, False: 0}\n",
    "# Income labels\n",
    "ca_labels_2014['PINCP'] = ca_labels_2014['PINCP'].map(mapping)\n",
    "ca_labels_2023['PINCP'] = ca_labels_2023['PINCP'].map(mapping)\n",
    "# Employment labels\n",
    "ca_labels_2023_em['ESR'] = ca_labels_2023_em['ESR'].map(mapping)\n",
    "ca_labels_2014_em['ESR'] = ca_labels_2014_em['ESR'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf75dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 missing data\n",
      " AGEP     0\n",
      "COW      0\n",
      "SCHL     0\n",
      "MAR      0\n",
      "OCCP     0\n",
      "POBP     0\n",
      "WKHP     0\n",
      "SEX      0\n",
      "RAC1P    0\n",
      "dtype: int64\n",
      "2023 missing data\n",
      " AGEP     0\n",
      "COW      0\n",
      "SCHL     0\n",
      "MAR      0\n",
      "OCCP     0\n",
      "POBP     0\n",
      "WKHP     0\n",
      "SEX      0\n",
      "RAC1P    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the features\n",
    "missing_count = ca_features_2014.isna().sum()\n",
    "print(\"2014 missing data\\n\",missing_count)\n",
    "\n",
    "missing_count = ca_features_2023.isna().sum()\n",
    "print(\"2023 missing data\\n\",missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ab59b",
   "metadata": {},
   "source": [
    "#### Mapping Occupation Codes to Occupation Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a33b139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_features_2014_merged = ca_features_2014.merge(df_OCCP[['code', 'category_code']], \n",
    "                            left_on='OCCP', right_on='code', how='left').drop(columns=['code']).rename(columns={'category_code': 'OCCP_CA'})\n",
    "ca_features_2023_merged = ca_features_2023.merge(df_OCCP[['code', 'category_code']],\n",
    "                            left_on='OCCP', right_on='code', how='left').drop(columns=['code']).rename(columns={'category_code': 'OCCP_CA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec224bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183941\n",
      "    OCCP_CA  Count\n",
      "0       1.0  23420\n",
      "1      15.0  19227\n",
      "2       0.0  19144\n",
      "3      12.0  11307\n",
      "4       4.0  10452\n",
      "5       2.0   9669\n",
      "6       3.0   9438\n",
      "7       9.0   9259\n",
      "8      16.0   8458\n",
      "9      18.0   7948\n",
      "10     17.0   7133\n",
      "11     21.0   5916\n",
      "12     13.0   5711\n",
      "13      6.0   5241\n",
      "14     19.0   4794\n",
      "15     22.0   4364\n",
      "16      7.0   3988\n",
      "17     11.0   3781\n",
      "18     10.0   3322\n",
      "19     20.0   3144\n",
      "20      5.0   2951\n",
      "21     14.0   2382\n",
      "22      8.0   2101\n",
      "23     24.0    660\n",
      "24     23.0    131\n"
     ]
    }
   ],
   "source": [
    "result = (ca_features_2014_merged.groupby('OCCP_CA').size().reset_index(name='Count')\n",
    "          .sort_values('Count', ascending=False).reset_index(drop=True))\n",
    "print(len(ca_features_2014_merged))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba37ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203278\n",
      "    OCCP_CA  Count\n",
      "0       0.0  23611\n",
      "1       1.0  20052\n",
      "2      15.0  17271\n",
      "3       4.0  14141\n",
      "4      12.0  12942\n",
      "5       9.0  11375\n",
      "6       2.0  10468\n",
      "7      21.0   9386\n",
      "8       3.0   8355\n",
      "9      18.0   8125\n",
      "10      6.0   8102\n",
      "11     10.0   7579\n",
      "12     13.0   6754\n",
      "13     17.0   6660\n",
      "14      7.0   5730\n",
      "15     16.0   5656\n",
      "16     19.0   4999\n",
      "17     22.0   4489\n",
      "18     11.0   3946\n",
      "19      5.0   3608\n",
      "20      8.0   3354\n",
      "21     20.0   2747\n",
      "22     14.0   2722\n",
      "23     24.0   1102\n",
      "24     23.0    104\n"
     ]
    }
   ],
   "source": [
    "result = (ca_features_2023_merged.groupby('OCCP_CA').size().reset_index(name='Count')\n",
    "          .sort_values('Count', ascending=False).reset_index(drop=True))\n",
    "print(len(ca_features_2023_merged))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62da6c7",
   "metadata": {},
   "source": [
    "## Data Analysis: Bias in Income Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446255c4",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9a96d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" statistical parity \"\"\"\n",
    "def calculate_demographic_parity_difference(df, y_pred, sensitive_attribute):\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"pred\"] = y_pred\n",
    "\n",
    "    group_probabilities = {}\n",
    "    unique_groups = df[sensitive_attribute].unique()\n",
    "    unique_groups.sort()\n",
    "\n",
    "    for group_val in unique_groups:\n",
    "        group_df = df[df[sensitive_attribute] == group_val]\n",
    "        prob_unfavorable_pred = (group_df[\"pred\"] == 1).mean()\n",
    "        group_probabilities[f\"P(pred=1 | {sensitive_attribute}={group_val})\"] = prob_unfavorable_pred\n",
    "\n",
    "    # Demographic Parity Difference\n",
    "    \n",
    "    probs = list(group_probabilities.values())\n",
    "    demographic_parity_diff = max(probs) - min(probs)\n",
    "\n",
    "    results = {\n",
    "        \"Demographic Parity Difference\": demographic_parity_diff\n",
    "    }\n",
    "    results.update(group_probabilities)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "004e9fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183941\n",
      "Race distribution of income in 2014\n",
      "\n",
      "        Count  Percentage\n",
      "RAC1P                    \n",
      "1.0    117209   63.720976\n",
      "6.0     28817   15.666437\n",
      "8.0     20706   11.256870\n",
      "2.0      8435    4.585710\n",
      "9.0      6649    3.614746\n",
      "3.0      1121    0.609435\n",
      "7.0       612    0.332715\n",
      "5.0       379    0.206044\n",
      "4.0        13    0.007067\n",
      "\n",
      "SEX distribution of income in 2014\n",
      "\n",
      "     Count  Percentage\n",
      "SEX                   \n",
      "1.0  98115   53.340473\n",
      "2.0  85826   46.659527\n",
      "\n",
      "Marital Status distribution of income in 2014\n",
      "\n",
      "     Count  Percentage\n",
      "MAR                   \n",
      "1.0  98382   53.485629\n",
      "5.0  60759   33.031787\n",
      "3.0  17655    9.598186\n",
      "4.0   3875    2.106654\n",
      "2.0   3270    1.777744\n"
     ]
    }
   ],
   "source": [
    "# Overall distribution of income in 2014\n",
    "print(len(ca_labels_2014))\n",
    "print('Race distribution of income in 2014\\n')\n",
    "race_counts = ca_features_2014['RAC1P'].value_counts()\n",
    "race_percents = ca_features_2014['RAC1P'].value_counts(normalize=True) * 100\n",
    "print(pd.concat([race_counts, race_percents], axis=1, keys=['Count', 'Percentage']))\n",
    "\n",
    "print('\\nSEX distribution of income in 2014\\n')\n",
    "sex_counts = ca_features_2014['SEX'].value_counts()\n",
    "sex_percents = ca_features_2014['SEX'].value_counts(normalize=True) * 100\n",
    "print(pd.concat([sex_counts, sex_percents], axis=1, keys=['Count', 'Percentage']))\n",
    "\n",
    "print('\\nMarital Status distribution of income in 2014\\n')\n",
    "mar_counts = ca_features_2014['MAR'].value_counts()\n",
    "mar_percents = ca_features_2014['MAR'].value_counts(normalize=True) * 100\n",
    "print(pd.concat([mar_counts, mar_percents], axis=1, keys=['Count', 'Percentage']))\n",
    "\n",
    "# ca_features_2023, ca_labels_2023,\n",
    "# ca_features_2014, ca_labels_2014,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871633f",
   "metadata": {},
   "source": [
    "### 1st Sensitive Attribute: Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75292a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race_Code</th>\n",
       "      <th>High_Income_Count</th>\n",
       "      <th>High_Income_Percentage</th>\n",
       "      <th>Race_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>45323</td>\n",
       "      <td>38.67</td>\n",
       "      <td>White alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2555</td>\n",
       "      <td>30.29</td>\n",
       "      <td>Black or African American alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>265</td>\n",
       "      <td>23.64</td>\n",
       "      <td>American Indian alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>23.08</td>\n",
       "      <td>Alaska Native alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>57</td>\n",
       "      <td>15.04</td>\n",
       "      <td>American Indian and Alaska Native tribes speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>11975</td>\n",
       "      <td>41.56</td>\n",
       "      <td>Asian alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>150</td>\n",
       "      <td>24.51</td>\n",
       "      <td>Native Hawaiian and Other Pacific Islander alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3025</td>\n",
       "      <td>14.61</td>\n",
       "      <td>Some other race alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1874</td>\n",
       "      <td>28.18</td>\n",
       "      <td>Two or More Races</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race_Code  High_Income_Count  High_Income_Percentage  \\\n",
       "0        1.0              45323                   38.67   \n",
       "1        2.0               2555                   30.29   \n",
       "2        3.0                265                   23.64   \n",
       "3        4.0                  3                   23.08   \n",
       "4        5.0                 57                   15.04   \n",
       "5        6.0              11975                   41.56   \n",
       "6        7.0                150                   24.51   \n",
       "7        8.0               3025                   14.61   \n",
       "8        9.0               1874                   28.18   \n",
       "\n",
       "                                    Race_Description  \n",
       "0                                        White alone  \n",
       "1                    Black or African American alone  \n",
       "2                              American Indian alone  \n",
       "3                                Alaska Native alone  \n",
       "4  American Indian and Alaska Native tribes speci...  \n",
       "5                                        Asian alone  \n",
       "6   Native Hawaiian and Other Pacific Islander alone  \n",
       "7                              Some other race alone  \n",
       "8                                  Two or More Races  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "df_income_14 = pd.concat([ca_features_2014, ca_labels_2014], axis=1)\n",
    "\n",
    "fairness_distribution = (\n",
    "    df_income_14.groupby('RAC1P')['PINCP']\n",
    "    .agg(\n",
    "        Count=lambda x: (x == 1).sum(),          # Number of high-income individuals among the group\n",
    "        Percentage=lambda x: (x == 1).mean() * 100  # Percentage of high-income individuals among the group\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values('RAC1P')\n",
    ")\n",
    "\n",
    "url = \"https://api.census.gov/data/2014/acs/acs1/pums/variables/RAC1P.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "values_dict = data['values']['item']\n",
    "df_race_labels = pd.DataFrame.from_dict(values_dict, orient='index', columns=['explanation'])\n",
    "df_race_labels = df_race_labels.reset_index().rename(columns={'index': 'code'})\n",
    "df_race_labels['code'] = df_race_labels['code'].astype(float)\n",
    "\n",
    "\n",
    "fairness_distribution_merged = fairness_distribution.merge(\n",
    "    df_race_labels[['code', 'explanation']],\n",
    "    left_on='RAC1P', right_on='code',\n",
    "    how='left'\n",
    ").drop(columns=['code'])\n",
    "\n",
    "\n",
    "fairness_distribution_merged = fairness_distribution_merged.rename(columns={\n",
    "    'RAC1P': 'Race_Code',\n",
    "    'explanation': 'Race_Description',\n",
    "    'Count': 'High_Income_Count',\n",
    "    'Percentage': 'High_Income_Percentage'\n",
    "})\n",
    "\n",
    "fairness_distribution_merged['High_Income_Percentage'] = (\n",
    "    fairness_distribution_merged['High_Income_Percentage'].round(2)\n",
    ")\n",
    "\n",
    "fairness_distribution_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a43f4",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f37b6",
   "metadata": {},
   "source": [
    "#### Split traning  and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0cd00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_14_income_train, x_14_income_test, y_14_income_train, y_14_income_test = train_test_split(ca_features_2014, ca_labels_2014, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba06c4",
   "metadata": {},
   "source": [
    "#### Regular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce39192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8301666258936095\n",
      "F1 Score: 0.7565651055871581\n",
      "\n",
      "Confusion Matrix in Table Form:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               20832                2889\n",
      "Actual Positive                3359                9709\n",
      "TP (True Positive): 9709\n",
      "FP (False Positive): 2889\n",
      "TN (True Negative): 20832\n",
      "FN (False Negative): 3359\n",
      "\n",
      "TPR (True Positive Rate/Recall): 0.7429599020508112\n",
      "FPR (False Positive Rate): 0.12179081826229923\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(x_14_income_train, y_14_income_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = model.predict(x_14_income_test)\n",
    "\n",
    "# evaluate the model\n",
    "acc = accuracy_score(y_14_income_test, y_pred)\n",
    "f1 = f1_score(y_14_income_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_14_income_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual Negative', 'Actual Positive'], \n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "print(\"\\nConfusion Matrix in Table Form:\")\n",
    "print(cm_df)\n",
    "print(\"TP (True Positive):\", tp)\n",
    "print(\"FP (False Positive):\", fp)\n",
    "print(\"TN (True Negative):\", tn)\n",
    "print(\"FN (False Negative):\", fn)\n",
    "\n",
    "tpr = tp / (tp + fn)  # TPR\n",
    "fpr = fp / (fp + tn)  # FPR\n",
    "\n",
    "print(\"\\nTPR (True Positive Rate/Recall):\", tpr)\n",
    "print(\"FPR (False Positive Rate):\", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae473c",
   "metadata": {},
   "source": [
    "##### No parameter tuning is needed, because he model's performance is already stable (metrics show low standard deviation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d17298af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: AVG 0.8322 (±0.0017)\n",
      "f1: AVG 0.7591 (±0.0027)\n",
      "recall: AVG 0.7459 (±0.0037)\n",
      "precision: AVG 0.7728 (±0.0025)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'recall', 'precision']\n",
    "\n",
    "\n",
    "cv_results = cross_validate(model, x_14_income_train, y_14_income_train,\n",
    "                          cv=5, scoring=scoring)\n",
    "\n",
    "\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric}: AVG {scores.mean():.4f} (±{scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da4fd364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: 0.3236\n",
      "P(pred=1 | RAC1P=1.0): 0.3803\n",
      "P(pred=1 | RAC1P=2.0): 0.2828\n",
      "P(pred=1 | RAC1P=3.0): 0.1638\n",
      "P(pred=1 | RAC1P=4.0): 0.3333\n",
      "P(pred=1 | RAC1P=5.0): 0.1026\n",
      "P(pred=1 | RAC1P=6.0): 0.4172\n",
      "P(pred=1 | RAC1P=7.0): 0.2063\n",
      "P(pred=1 | RAC1P=8.0): 0.0937\n",
      "P(pred=1 | RAC1P=9.0): 0.2601\n"
     ]
    }
   ],
   "source": [
    "result = calculate_demographic_parity_difference(x_14_income_test, y_pred, sensitive_attribute='RAC1P')\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89beea5b",
   "metadata": {},
   "source": [
    "#### Without the protected attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03f4c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:25:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8301666258936095\n",
      "F1 Score: 0.7567925262748151\n",
      "\n",
      "Confusion Matrix in Table Form:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               20820                2901\n",
      "Actual Positive                3347                9721\n",
      "TP (True Positive): 9721\n",
      "FP (False Positive): 2901\n",
      "TN (True Negative): 20820\n",
      "FN (False Negative): 3347\n",
      "\n",
      "TPR (True Positive Rate/Recall): 0.7438781756963575\n",
      "FPR (False Positive Rate): 0.12229669912735551\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_2 = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "x_14_income_norace_train = x_14_income_train.drop([\"RAC1P\"], axis=1)\n",
    "model_2.fit(x_14_income_norace_train, y_14_income_train)\n",
    "\n",
    "# predict on the test set\n",
    "\n",
    "x_14_income_norace_test = x_14_income_test.drop([\"RAC1P\"], axis=1)\n",
    "y_norace_pred = model_2.predict(x_14_income_norace_test)\n",
    "\n",
    "# evaluate the model\n",
    "acc = accuracy_score(y_14_income_test, y_norace_pred)\n",
    "f1 = f1_score(y_14_income_test, y_norace_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_14_income_test, y_norace_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual Negative', 'Actual Positive'], \n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "print(\"\\nConfusion Matrix in Table Form:\")\n",
    "print(cm_df)\n",
    "print(\"TP (True Positive):\", tp)\n",
    "print(\"FP (False Positive):\", fp)\n",
    "print(\"TN (True Negative):\", tn)\n",
    "print(\"FN (False Negative):\", fn)\n",
    "\n",
    "tpr = tp / (tp + fn)  # TPR\n",
    "fpr = fp / (fp + tn)  # FPR\n",
    "\n",
    "print(\"\\nTPR (True Positive Rate/Recall):\", tpr)\n",
    "print(\"FPR (False Positive Rate):\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0798fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: 0.5641\n",
      "P(pred=1 | RAC1P=1.0): 0.3744\n",
      "P(pred=1 | RAC1P=2.0): 0.3067\n",
      "P(pred=1 | RAC1P=3.0): 0.2155\n",
      "P(pred=1 | RAC1P=4.0): 0.6667\n",
      "P(pred=1 | RAC1P=5.0): 0.1410\n",
      "P(pred=1 | RAC1P=6.0): 0.4221\n",
      "P(pred=1 | RAC1P=7.0): 0.2222\n",
      "P(pred=1 | RAC1P=8.0): 0.1025\n",
      "P(pred=1 | RAC1P=9.0): 0.2911\n"
     ]
    }
   ],
   "source": [
    "result_norace = calculate_demographic_parity_difference(x_14_income_test, y_norace_pred, sensitive_attribute='RAC1P')\n",
    "for key, value in result_norace.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857823ff",
   "metadata": {},
   "source": [
    "#### Pre-processing: Reweighing\n",
    "Train and test a classifier with weights (see lecture slide for the weight calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa5969ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9610.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5550.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183936</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4720.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183937</th>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183938</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183939</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183940</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183941 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGEP  COW  SCHL  MAR    OCCP   POBP  WKHP  SEX  RAC1P  PINCP\n",
       "0       36.0  1.0  16.0  5.0  9610.0   22.0  35.0  1.0    1.0      0\n",
       "1       47.0  1.0  20.0  3.0  5700.0   39.0  60.0  2.0    1.0      0\n",
       "2       20.0  1.0  19.0  5.0  4840.0    6.0  40.0  1.0    1.0      0\n",
       "3       31.0  1.0  19.0  1.0  5120.0    6.0  45.0  2.0    1.0      1\n",
       "4       31.0  5.0  19.0  1.0  5550.0    6.0  40.0  1.0    1.0      0\n",
       "...      ...  ...   ...  ...     ...    ...   ...  ...    ...    ...\n",
       "183936  63.0  1.0  19.0  3.0  4720.0  313.0  40.0  2.0    8.0      0\n",
       "183937  38.0  3.0  20.0  5.0  3320.0    6.0  40.0  1.0    8.0      1\n",
       "183938  40.0  1.0  21.0  1.0  6440.0    6.0  30.0  2.0    1.0      0\n",
       "183939  40.0  3.0  20.0  1.0  3740.0    6.0  56.0  1.0    1.0      1\n",
       "183940  19.0  1.0  18.0  5.0  4600.0    6.0  12.0  2.0    1.0      0\n",
       "\n",
       "[183941 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2f70201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight = P_exp / P_obs:\n",
      "(1.0, 0): 1.0523\n",
      "(1.0, 1): 0.9170\n",
      "(2.0, 0): 0.9258\n",
      "(2.0, 1): 1.1707\n",
      "(3.0, 0): 0.8452\n",
      "(3.0, 1): 1.5001\n",
      "(4.0, 0): 0.8390\n",
      "(4.0, 1): 1.5366\n",
      "(5.0, 0): 0.7596\n",
      "(5.0, 1): 2.3578\n",
      "(6.0, 0): 1.1043\n",
      "(6.0, 1): 0.8533\n",
      "(7.0, 0): 0.8549\n",
      "(7.0, 1): 1.4468\n",
      "(8.0, 0): 0.7558\n",
      "(8.0, 1): 2.4273\n",
      "(9.0, 0): 0.8987\n",
      "(9.0, 1): 1.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8254097692244965\n",
      "F1 Score: 0.749326776724037\n",
      "\n",
      "Confusion Matrix in Table Form:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative               20766                2955\n",
      "Actual Positive                3468                9600\n",
      "TP (True Positive): 9600\n",
      "FP (False Positive): 2955\n",
      "TN (True Negative): 20766\n",
      "FN (False Negative): 3468\n",
      "\n",
      "TPR (True Positive Rate/Recall): 0.7346189164370982\n",
      "FPR (False Positive Rate): 0.12457316302010876\n"
     ]
    }
   ],
   "source": [
    "# W（X）= P_exp（A，Y）/P_obs（A，Y）\n",
    "def calculate_weights(df, sensitive_attr, target_attr):\n",
    "    P_A = df.groupby(sensitive_attr).size() / len(df)\n",
    "    P_Y = df[target_attr].value_counts(normalize=True)\n",
    "    \n",
    "    # P_exp(A,Y) = P(A) * P(Y)\n",
    "    P_exp = {}\n",
    "    for a in P_A.index:\n",
    "        for y in P_Y.index:\n",
    "            P_exp[(a, y)] = P_A[a] * P_Y[y]\n",
    "    \n",
    "    # P_obs(A,Y)\n",
    "    P_obs = df.groupby([sensitive_attr, target_attr]).size() / len(df)\n",
    "\n",
    "    # print(\"\\nP_exp(A,Y):\")\n",
    "    # for key, value in P_exp.items():\n",
    "    #     print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # print(\"\\nP_obs(A,Y):\")\n",
    "    # for key, value in P_obs.items():\n",
    "    #     print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nWeight = P_exp / P_obs:\")\n",
    "    for key in P_exp:\n",
    "        obs = P_obs.get(key)\n",
    "        print(f\"{key}: {P_exp[key]/obs:.4f}\")\n",
    "    \n",
    "    df['weight'] = df.apply(\n",
    "        lambda row: P_exp[(row[sensitive_attr], row[target_attr])] / P_obs.get((row[sensitive_attr], row[target_attr]), 1), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "compas_data_weighted = calculate_weights(df_income_14, \"RAC1P\", \"PINCP\")\n",
    "\n",
    "\n",
    "# Train the model with weighted data\n",
    "model_3 = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model_3.fit(x_14_income_train, y_14_income_train, sample_weight=compas_data_weighted.loc[x_14_income_train.index, \"weight\"])\n",
    "\n",
    "# predict on the test set\n",
    "y_pred_weight = model_3.predict(x_14_income_test)\n",
    "\n",
    "# evaluate the model\n",
    "acc = accuracy_score(y_14_income_test, y_pred_weight)\n",
    "f1 = f1_score(y_14_income_test, y_pred_weight)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_14_income_test, y_pred_weight)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual Negative', 'Actual Positive'], \n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "print(\"\\nConfusion Matrix in Table Form:\")\n",
    "print(cm_df)\n",
    "print(\"TP (True Positive):\", tp)\n",
    "print(\"FP (False Positive):\", fp)\n",
    "print(\"TN (True Negative):\", tn)\n",
    "print(\"FN (False Negative):\", fn)\n",
    "\n",
    "tpr = tp / (tp + fn)  # TPR\n",
    "fpr = fp / (fp + tn)  # FPR\n",
    "\n",
    "print(\"\\nTPR (True Positive Rate/Recall):\", tpr)\n",
    "print(\"FPR (False Positive Rate):\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "53b4f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Difference: 0.2163\n",
      "P(pred=1 | RAC1P=1.0): 0.3603\n",
      "P(pred=1 | RAC1P=2.0): 0.3103\n",
      "P(pred=1 | RAC1P=3.0): 0.2672\n",
      "P(pred=1 | RAC1P=4.0): 0.3333\n",
      "P(pred=1 | RAC1P=5.0): 0.1667\n",
      "P(pred=1 | RAC1P=6.0): 0.3830\n",
      "P(pred=1 | RAC1P=7.0): 0.2937\n",
      "P(pred=1 | RAC1P=8.0): 0.2106\n",
      "P(pred=1 | RAC1P=9.0): 0.2997\n"
     ]
    }
   ],
   "source": [
    "result = calculate_demographic_parity_difference(x_14_income_test, y_pred_weight, sensitive_attribute='RAC1P')\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
